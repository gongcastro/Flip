---
appendix: flip_manuscript_appendix.Rmd
output: pdf_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(papaja)
library(dplyr)
library(tibble)
library(ggplot2)
library(knitr)
library(kableExtra)
library(purrr)
library(here)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Seed for random number generation
knitr::opts_chunk$set(
  cache.extra = knitr::rand_seed,
  out.width = "\\textwidth",
  results = "asis",
  fig.cap = "Output of the Linear Mixed-Effects model on subsets of the data. Coefficients of each model are reported for each fixed effects. Standard error of the mean and 95\\% confidence intervals are represented as black whiskers and shaded boxes, respectively."
)

# import data
dat   <- read.csv(here("Data", "01_data-processed.csv")) # raw data

# import LMEM results
anova  <- read.csv(here("Data", "03_anova-merged.csv"))
anova6 <- read.csv(here("Data", "02_results-lmem.csv"))
anova5 <- read.csv(here("Data", "HPP5", "02_results-lmem-5.csv"))
anova4 <- read.csv(here("Data", "HPP4", "02_results-lmem-4.csv"))
anova3 <- read.csv(here("Data", "HPP3", "02_results-lmem-3.csv"))
anova2 <- read.csv(here("Data", "HPP2", "02_results-lmem-2.csv"))



n_HPP2 <- dat %>% filter(hpp<3) %>% distinct(participant) %>% nrow()
n_HPP3 <- dat %>% filter(hpp<4) %>% distinct(participant) %>% nrow()
n_HPP4 <- dat %>% filter(hpp<5) %>% distinct(participant) %>% nrow()
n_HPP5 <- dat %>% filter(hpp<6) %>% distinct(participant) %>% nrow()
n_HPP6 <- dat %>% distinct(participant) %>% nrow()

```


## S1: Experiments included in the linear mixed-effects model. 

The selected experiments consist of an artificial grammar learning task with 12-month-old infants. These experiments are characterized by variability in the number of infants’ prior HPP visits^[At the time of publication of @saffran2003, the first author noted that there appeared to be an association between the number of prior studies completed by the infants and the direction of preference. The analysis was included in the original manuscript submission but was removed from later revisions based on reviewer suggestions.]. They include all studies run in the two senior authors’ labs that included (a) 11- to 13-month-old participants; (b) HPP; (c) artificial grammar learning (linguistic or non-linguistic); (d) 2 to 5 minutes of exposure; (e) an *a priori* hypothesis that infants would show learning; (f) visit numbers recorded at the time of testing. The studies are thus as well matched as is possible given the retrospective nature of this analysis. 


*@saffran2003* demonstrated that 12-month-old infants can compute multiple regularities from a finite-state grammar. Infants were able to first segment words from running speech based on transitional probabilities, then detect permissible orderings of the segmented words. Test items consisted of grammatical and ungrammatical sentences that could only be discriminated based on word-level information (transitional probabilities between syllables were not informative about the "grammaticality" of test items). Infants showed a significant familiarity preference: *F*(`r printnum(1, digits = 0)`, `r printnum(38, digits = 0)`)= `r printnum(5.37, digits = 2)`, *p* < .05.

*Saffran, Hauser, Seibel, Kapfhamer, Tsao, & Cushman (2008)* demonstrated that infants could detect simple phrases (i.e., clusters of nonsense words grouped together based on statistical regularities) from artificial grammars. In Exp. 1, infants in the Predictive Language condition were familiarized with a grammar including predictive (statistical) dependencies between words. The test items consisted of familiar sentences vs. novel sentences violating the grammar. Infants showed a significant novelty preference: *t*(`r printnum(11, digits = 0)`) = `r printnum(2.52, digits = 2)`, *p* < .05.

*@santolin2019* is a conceptual replication of @saffran2008 using non-linguistic sounds (e.g., computer alert sounds) to implement the grammars. Infants exposed to the Predictive language showed a significant novelty preference: *t*(`r printnum(26, digits = 0)`) = `r printnum(2.45, digits = 2)`, *p* = `r printp(0.021, digits = 3)`, *d* = `r printnum(0.47, digits = 2)`.
	
*@santolin2019* is a conceptual replication of @saffran2008 using non-linguistic sounds (e.g., computer alert sounds) to implement the grammars. Infants exposed to the Predictive language showed a significant novelty preference: *t*(`r printnum(26, digits = 0)`)=`r printnum(2.45, digits = 2)`, *p*=`r printp(0.021, digits = 3)`, *d*=`r printnum(0.47, digits = 2)`.

We replicated the Predictive Language condition of @santolin2019 at the University Pompeu Fabra, Barcelona (*Santolin, Saffran & Sebastian-Galles, 2019*)[-@santolin2019a], using identical stimuli and procedures. We found significant discrimination of the test stimuli but observed the opposite direction of preference: infants listened longer to familiar than novel strings: *t*(`r printnum(23, digits = 0)`) = `r printnum(2.303, digits = 2)`, *p* = `r printp(0.03, digits = 3)`, *d* = `r printnum(0.47, digits = 2)`. All results are shown in Figure 1 of the main manuscript. 


## S2: Participants information

We retrieved data from `r printnum(n_HPP6)` infants who had participated in a range of 1-6 HPP visits. Three of the experiments were run in Madison, WI (University of Wisconsin-Madison): Saffran & Wilson, 2003 (Exp. 2; *N*=`r printnum(table(filter(dat, item=="1")$study)[1])`, mean age: 11.5 months); Saffran et al., 2008 (Exp. 1, Condition P-Language: *N*=`r printnum(table(filter(dat, item=="1")$study)[2])`, mean age: 12.8 months); Santolin & Saffran, 2019 (Condition 1; *N*=`r printnum(table(filter(dat, item=="1")$study)[3])`, mean age: 12.9 months). One study was run in Barcelona, Spain (Universitat Pompeu Fabra): Santolin, Saffran & Sebastian-Galles, 2019 (*N*=`r printnum(table(filter(dat, item=="1")$study)[4])`, mean age: 13 months).


## S3: Linear mixed-effects model - additional information

We fit a model predicting looking time ($LT$) including $Item$ (Familiar vs. Novel), number of Head-turn Preference Procedure experiments completed by infants ($HPP$), and their interaction ($Item \times HPP$) as fixed effects. Participant and study [4 levels: Santolin & Saffran (2019), Santolin, Saffran & Sebastian-Galles (2019), Saffran et al. (2008), Saffran & Wilson (2003)] were included as random effects. Following @barr2013, we fit a model with the maximal random effects structure including random intercepts by-participant and by-study, and random slopes of $HPP$ by-participant and by-study. However, due to lack of convergence, we pruned the random effects structure until convergence was achieved [e.g., @brauer2018]. The final model included by-participant and by-study random intercepts only. This model accounts for cross-participant variability in overall looking time (as some infants look longer than others), and for cross-study differences in overall looking time. The model was fit using the `lme4` R package [@bates2015a]. We used the `Anova` function from the `car` R package [@fox2019] to perform *F*-tests on fixed effects using Kenward-Roger’s approximation of the degrees of freedom [e.g., @judd2012]. 


## S4: Results sub-setting data to participants with less than 6, 5, 4, and 3 HPP studies

Consistent with the results of the entire dataset, we found a statistically significant interaction of *Test Item* with the number of *HPP* visits when reducing the sample to the infants who participated in less than 6, 5, 4, and 3 HPP experiments. Below, a table reporting the output of the linear mixed-effects model fitted on the original and reduced samples (Table S4.1). 


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results="asis"}

anova %>%
  mutate(term = rep(c("*Intercept*", "*Test Item*", "*HPP*", "*Test Item $\\times$ HPP*"), 5),
         p = printp(anova$p)) %>%
  mutate_at(c(3, 5, 6, 7), ~printnum(., digits = 1)) %>%
  arrange(desc(subset)) %>%
  mutate(subset = c("Original", "", "", "", "HPP 1-5", "", "", "","HPP 1-4", "", "", "","HPP1-3", "", "", "", "HPP 1-2", "", "", "")) %>%
  select(subset, term, estimate, std_error, ci95, f, df_res, p) %>%
  kable(format = "pandoc",
        col.names = c("**Subset**", "**Term**", "**Coefficient**", "***SEM***", "**95\\% CI**", "**F**", "**Den. *df***", "***p***"), 
        align = "c",
        digits = 1)

```

In all models, the $Item \times HPP$ interaction term was statistically significant [HPP 1-5: *F*(`r printnum(anova5$df[4], digits=0)`, `r printnum(anova5$df_res[4], digits=0)`) = `r printnum(anova5$f[4], digits=2)`, *p* = `r printp(anova5$p[4])`; HPP 1-4: *F*(`r printnum(anova4$df[4], digits=0)`, `r printnum(anova4$df_res[4], digits=0)`) = `r printnum(anova4$f[4], digits=2)`, *p* = `r printp(anova4$p[4])`; HPP 1-3: *F*(`r printnum(anova3$df[4], digits=0)`, `r printnum(anova3$df_res[4], digits=0)`) = `r printnum(anova3$f[4], digits=2)`, *p* = `r printp(anova3$p[4])`; HPP 1-2: *F*(`r printnum(anova2$df[4], digits=0)`, `r printnum(anova2$df_res[4], digits=0)`) = `r printnum(anova2$f[4], digits=2)`, *p* = `r printp(anova2$p[4])`] . These results provide evidence that the effect of HPP on the preference pattern we observed in our main analysis is not entirely dependent on any subsample of the HPP variable.

```{r message=FALSE, warning=FALSE, paged.print=FALSE, echo=FALSE, fig.cap="Graphical representation of the coefficients of the Test Item by HPP visits interaction term of the model fitted on the complete data-set (reported in the main manuscript), and of the models fitted on the reduced data-sets. Black dots represent the point estimate of the coefficient, black whiskers represent the standard error of the mean, and grey boxes represent the bootstrapped 95\\% confidence interval around the point estimate."}

include_graphics(here("Figures", "05_anova-merged.png"))

```

# Session info

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

sessionInfo()

```

## References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>

\endgroup

