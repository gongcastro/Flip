---
title: "Methods (HPP5)"
output:
  pdf_document:
    fig_caption: yes
  word_document:
    reference_docx: flip_template.docx
bibliography: "../Flip.bib"
csl: "../apa.csl"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	include = TRUE,
	out.width = "100%"
)
options(knitr.kable.NA = '-', big.mark = ',') # to replace "NA" with "-" in knitr::kable

```

```{r prepare, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# load packages
library(tidyverse)    # tidyverse packages
library(magrittr)     # for using pipes
library(knitr)        # for formatting tables
library(english)      # for transforming numbers to words
library(here)         # for locating files

# import data
data      <- read.table(here("Data", "01_data-processed-5.csv"), header = TRUE, sep = ",", dec = ".")
anova     <- read.table(here("Data", "02_results-lmem-5.csv"), header = TRUE, sep = ",", dec = ".")
effects   <- read.table(here("Data", "02_results-effects-5.csv"), header = TRUE, sep = ",", dec = ".")
posterior <- scan(here("Data", "02_results-posterior-5.txt"))
tolerance <- read.table(here("Data", "02_results-multicollinearity-5.csv"), header = TRUE, sep = ",", dec = ".")

```

## Participants

```{r participants, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

# number of observations
n <- data %>% summarise(n = n())                                  
# number of participants
n_participants <- data %>% filter(Item == "Novel") %>% summarise(n = n()) 
# number of participants by study
n_study <- data %>%                                                           
  filter(Item == "Novel") %>%
  group_by(Study, Location) %>%
  summarise(n = n())
# number of participants by study and location
n_studyLocation <- data %>%
  filter(Item == "Novel") %>%
  group_by(Study, Location) %>%
  summarise(n = n())

```

We retrieved data from `r n_participants$n` participants: `r n_study$n[1]` from @santolin2019a, `r n_studyLocation$n[2]` tested in Wisconsin, `r n_studyLocation$n[1]` tested in the replication study @santolin2019 tested in Barcelona, and `r n_studyLocation$n[3]` from @saffran2003, tested in Wisconsin. Two datapoints were available for each participant: one for the mean looking time in "familiar" trials, and one for the mean looking time in "novel" trials. A total of `r n$n` datapoints were included in the analysis. Participants included in our analysis were those included in the final version of both studies.

## Studies

The two studies conducted by Santolin and colleages compared looking times in novel and familiar trials, and revealed that infants displayed a preference toward one of the trial types. The direction of the preference, however, was different for the two studies.

```{r plot_data, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align="c", fig.cap="Looking time (ms) in familiar and novel trials split by Study and Location. Error bars indicate the standard error of the mean, respectively. Grey lines indicate participant level mean looking times."}

include_graphics(here("Figures", "01_lookingtimes-study.png"))

```

## Data analysis

We fit a model predicting looking time ($LT$) from the fixed effects of test item ($Item$, Familiar vs. Novel), the number of HeadTurn Preference Procedure experiments completed by infants ($HPP$), and their interaction ($Item \times HPP$) as fixed effects. *Familiar* trials were set as the baseline. Participant ($Participant$) and study ($Study$) were included as random effects. Following @barr2013, we fit a model with the maximal random effects structure that allowed the model to converge. The maximal random effects structure included by-participant and by-study random intercepts and by-participant and by-study random slopes of $HPP$. Due to lack of convergence, we subsequently pruned the random effects structure until convergence was achieved. The final model included by-participant and by-study random intercepts. The particular random effects structure chosen does not qualitatively impact the estimates and conclusions from the model.

This model accounts for cross-participants variability in overall looking time (i.e. some infants are long lookers, some are short lookers), and for cross-studies differences in overall looking time, and allows the effect of $HPP$ to vary across studies. We specifiyied by-study random effects for two strong reasons. First, participants from different linguistic/cultural environments were included in both studies. This may have led to participants in one of the locations to looking longer in average than those from the other location. Second, in spite of their similarity both studies were not identical, which could also have led to differences in overall looking time.

```{r model, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE,}

anova %>%
  mutate(term = c("Intercept", "Item", "HPP", "Item * HPP")) %>%
  select(term, Coefficient, SEM, CI95, F, Df.res, p) %>%
  kable(digits = 3, col.names = c("Term", "Coefficient", "SEM", "95% CI", "F", "Den df", "p"), align = "c",
        caption = "Estimates of the linear mixed-effects model and outcomes of the Kenward-Roger F-tests performed on fixed effects. 95% confidence intervals were bootstrapped.") 

```

We found a statistically significant interaction term, *F*(`r round(anova$Df[4], 2)`, `r round(anova$Df.res[4], 2)`) = `r round(anova$F[4], 2)`, *p* = `r round(anova$p[4], 3)`, 95% CI = [`r anova$CI95[4]`], suggesting that the effect of trial type on looking time was influenced by the number of HPP experiments each participant participated in. The interaction shows that experience with a higher number of HPP experiments is associated with a stronger novelty preference.

```{r plot_model, echo=FALSE, message=FALSE, warning=FALSE, fig.align='c', fig.cap="Looking times of familiar and novel trials, split by number of HeadTurn Preference Procedure experiments. Black points and error bars represent the group-level mean looking time and SEM, respectively. Grey lines represent participant-level mean looking time."}

include_graphics(here("Figures", "02_lookingtimes-hpp.png"))

```


```{r interaction, echo=FALSE, message=FALSE, warning=FALSE, fig.align="c", fig.cap="Predicted looking times plotted against HPP, split by test item."}

include_graphics(here("Figures", "03_interaction.png"))
```


# Appendices

### Appendix 1: Linear Mixed Model

Following @barr2013 guidelines, we initially specified a maximal random structure, including random intercepts for $Participant$ and $Study$, and random slopes for $Item$, $HPP$, and $Item \times HPP$, by $Participant$ and $Study$. Due to lack of convergence, the random structure was simplified until the model converged successfully and fit was no longer singular. The final model included only by-participant and by-study random intercepts. The code and formula of the resulting mode are presented below:

<center>`LookingTime ~ Item * HPP + (1 | Participant) + (1 | Study)`</center>

$$ \begin{aligned}LT_{ips} = \\ &\beta_{0} + Participant_{0p} + Study_{0s} + \\ &\beta_{1} \times HPP_{i} + \\ &\beta_{2} \times Item_{i} + \\ &\beta_{3} \times (HPP \times Item_{i}) + \\ &e_{ips},e_{ips} \sim N(0, \sigma^2), Participant_{0p} \sim N(0, \tau_{00}^2), Study_{0p} \sim N(0, &\omega_{00}^2)\end{aligned}$$

Where:

* $LT_{ips}$ is the looking time in trial $i$, in participant $p$ from study $s$
* $\beta_{0}$ is the fixed intercept (the grand mean of all looking times from all trials)
* $Participant_{0p}$ is the by-participant random intercept (the overall looking time of participant $p$, assumed to have been sampled from a normal distribution with mean 0 and variance $\tau_{00}^2$
* $Study_{0s}$ is the by-study random intercept (the overall looking time in study $s$, assumed to have been sampled from a normal distribution with mean 0 and variance $\omega_{00}^2$.
* $\beta_{1}$ is the coefficient of the fixed effect of the $HPP$ predictor
* $\beta_{2}$ is the coefficient of the fixed effect of the $Item$ predictor
* $\beta_{3}$ is the coefficient of the fixed effect of the $Item \times HPP$ interaction
* $e_{ips}$ is the error of the model in trial $i$, of participant $p$ from study $s$, assumed to be normally distributed with mean 0 and variance $\sigma^2$

The model was fit using the `lme4` R package [@lme4]. We used the `Anova` function from the `car` R package [@fox2019] to *F*-tests to fixed effects in the model using Kenward-Roger's [@kenward2009] approximation to degrees of freedom.

Posterior predicted simulations [@gelman2006data] indicated that the coefficients obtained by our model are plausible: The observed inter-quartile range (IQR) of looking times lied within the IQR obtained from 1000 simulated datasets generated from the model in more than 95% of the simulations (*p* = `r round(posterior, 3)`).

### Appendix 2: Checking assumptions of the Linear Mixed Model

Residuals seem to approximate a normal distribution, though the distributions in the @santolin2019a and @santolin2019 studies seem to be somewhat skewed.

```{r normality, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

include_graphics(here("Figures", "04_model-assumptions-normality.png"))

```


```{r linearity_homoskedasticity, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

include_graphics(here("Figures", "04_model-assumptions-homoskedasticity.png"))

```

We observed little evidence of multicollinearity in the predictors we included in the model:

```{r multicollinearity, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

kable(tolerance, digits = 2, col.names = c("Term", "VIF", "Tolerance"), align = "c")

``` 

## References

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent
